from typing import Union, List, Optional

from pyspark.sql.types import StructType, StructField, StringType, DataType


# This file is auto-generated by generate_schema so do not edit manually
# noinspection PyPep8Naming
class TimingRepeatSchema:
    """
    Specifies an event that may occur multiple times. Timing schedules are used to
    record when things are expected or requested to occur. The most common usage
    is in dosage instructions for medications. They are also used when planning
    care of various kinds.
    If the element is present, it must have a value for at least one of the
    defined elements, an @id referenced from the Narrative, or extensions
    """

    # noinspection PyDefaultArgument
    @staticmethod
    def get_schema(
        max_nesting_depth: Optional[int] = 6,
        nesting_depth: int = 0,
        nesting_list: List[str] = [],
        max_recursion_limit: Optional[int] = 2,
        include_extension: Optional[bool] = False,
        extension_fields: Optional[List[str]] = [
            "valueBoolean",
            "valueCode",
            "valueDate",
            "valueDateTime",
            "valueDecimal",
            "valueId",
            "valueInteger",
            "valuePositiveInt",
            "valueString",
            "valueTime",
            "valueUnsignedInt",
            "valueUri",
            "valueQuantity",
        ],
        extension_depth: int = 0,
        max_extension_depth: Optional[int] = 2,
    ) -> Union[StructType, DataType]:
        """
        Specifies an event that may occur multiple times. Timing schedules are used to
        record when things are expected or requested to occur. The most common usage
        is in dosage instructions for medications. They are also used when planning
        care of various kinds.
        If the element is present, it must have a value for at least one of the
        defined elements, an @id referenced from the Narrative, or extensions


            id: None
            extension: May be used to represent additional information that is not part of the basic
        definition of the element. In order to make the use of extensions safe and
        manageable, there is a strict set of governance  applied to the definition and
        use of extensions. Though any implementer is allowed to define an extension,
        there is a set of requirements that SHALL be met as part of the definition of
        the extension.
            boundsQuantity: None
            boundsRange: None
            boundsPeriod: None
            count: A total count of the desired number of repetitions.
            duration: How long this thing happens for when it happens.
            durationMax: The upper limit of how long this thing happens for when it happens.
            durationUnits: The units of time for the duration, in UCUM units.
            frequency: The number of times to repeat the action within the specified period / period
        range (i.e. both period and periodMax provided).
            frequencyMax: If present, indicates that the frequency is a range - so repeat between
        [frequency] and [frequencyMax] times within the period or period range.
            period: Indicates the duration of time over which repetitions are to occur; e.g. to
        express "3 times per day", 3 would be the frequency and "1 day" would be the
        period.
            periodMax: If present, indicates that the period is a range from [period] to [periodMax],
        allowing expressing concepts such as "do this once every 3-5 days.
            periodUnits: The units of time for the period in UCUM units.
            when: A real world event that the occurrence of the event should be tied to.
        """
        if (
            max_recursion_limit
            and nesting_list.count("TimingRepeat") >= max_recursion_limit
        ) or (max_nesting_depth and nesting_depth >= max_nesting_depth):
            return StructType([StructField("id", StringType(), True)])
        # Return at least one field in the struct or Spark throws an error
        # "Datasource does not support writing empty or nested empty schemas"
        return StructType([StructField("id", StringType(), True)])
